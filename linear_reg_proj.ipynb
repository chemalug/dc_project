{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final Curso Ciencia de datos en python \n",
    "## Objetivo:\n",
    "#### Desarrollar un modelo predictivo desde los conceptos básicos, implementando el algoritmo de regresión lineal desde cero,<br> tomando en cuenta la optimización de los parametros con el descenso de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Configuración del entorno\n",
    "### Instalación de paquetes principales para el desarrollo\n",
    "* ipykernel: para el manejo del entorno en jupiter notebook \n",
    "* Numpy: para el manejo de operaciones mátematicas, vectoriales o de matrices\n",
    "* Pandas: para el tratamiento de dataframes\n",
    "* Matplotlib: Para la integración de graficos en el EDA\n",
    "* Seaborn: soporte para matplotlib\n",
    "* Scikit-learn: para pruebas de eficiencia del modelo resultante o modelado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipykernel numpy pandas matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Carga de los datos y división del mismo\n",
    "* Cargar los datos a un dataframe \n",
    "* Separar los datos en entrenamiento y validación en proporción de 80% y 20% respctivamente, usando slicing de Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset (1460, 6)\n",
      "Train data shape: (1168, 6)\n",
      "Validation data shape: (292, 6)\n"
     ]
    }
   ],
   "source": [
    "# Dividir el arreglo en 80% para entrenamiento y 20% para validación\n",
    "data_array = np.load('proyecto_training_data.npy') # Cargar el archivo\n",
    "print(\"Tamaño del dataset\", data_array.shape)\n",
    "\n",
    "n_train = int(data_array.shape[0] * 0.8) # Definiiendo el 80% para entrenamiento\n",
    "train_data = data_array[:n_train, :] # Definiendo el dataset de entrenamiento\n",
    "val_data = data_array[n_train:, :] # Definiendo el dataset de validación\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
